{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Bagging scratch code in our lecture such that:\n",
    "- Calculate for oob evaluation for each bootstrapped dataset, and also the average score\n",
    "- Change the code to \"without replacement\"\n",
    "- Put everything into a class <code>Bagging</code>.  It should have at least two methods, <code>fit(X_train, y_train)</code>, and <code>predict(X_test)</code>\n",
    "- Modify the code from above to randomize features.  Set the number of features to be used in each tree to be <code>sqrt(n)</code>, and then select a subset of features for each tree.  This can be easily done by setting our DecisionTreeClassifier <code>max_features</code> to 'sqrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for oob evaluation for each bootstrapped dataset, and also the average score\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random, math\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, B, bootstrap_ratio, with_no_replacement=True):\n",
    "        self.B = B    \n",
    "        self.bootstrap_ratio = bootstrap_ratio\n",
    "        self.with_no_replacement = with_no_replacement\n",
    "        self.tree_params = {'max_depth': 2, 'max_features': 'sqrt'}  #rmse return math.sqrt\n",
    "        self.models = [DecisionTreeClassifier(**self.tree_params) for _ in range(B)]\n",
    "\n",
    "    # 1. X_train, y_train\n",
    "    def fit(self, X, y):  \n",
    "        m, n = X.shape\n",
    "\n",
    "        #sample size for each tree\n",
    "        sample_size = int(self.bootstrap_ratio * len(X))\n",
    "\n",
    "        xsamples = np.zeros((self.B, sample_size, n))\n",
    "        ysamples = np.zeros((self.B, sample_size))\n",
    "\n",
    "        # use list because length is not known           #<-- Out of bag : keep in list\n",
    "        xsamples_oob = []  \n",
    "        ysamples_oob = []\n",
    "       \n",
    "        #bootstrapping samples (subsam) for each model\n",
    "        for i in range(self.B):\n",
    "            oob_idx = []\n",
    "            idxes = []       \n",
    "            for j in range(sample_size):\n",
    "                idx = random.randrange(m)             # with replacement\n",
    "                if (self.with_no_replacement):        # with no replace : oob\n",
    "                    while idx in idxes:                    # we have to keep track what the indexes're already used\n",
    "                        idx = random.randrange(m)\n",
    "                idxes.append(idx)           \n",
    "                oob_idx.append(idx)\n",
    "                \n",
    "                xsamples[i, j, :] = X[idx]\n",
    "                ysamples[i, j] = y[idx]\n",
    "                #keep track of idx that i did not use for ith tree\n",
    "                \n",
    "            mask = np.zeros((m), dtype=bool)           ##keep b(can see) and oob\n",
    "            #print(mask)\n",
    "            mask[oob_idx] = True\n",
    "            #print(mask[oob_idx])\n",
    "            \n",
    "            xsamples_oob.append(X[~mask])\n",
    "            ysamples_oob.append(y[~mask])\n",
    "        #print(xsamples_oob)\n",
    "        #print(ysamples_oob)\n",
    "              \n",
    "     #fitting each estimator\n",
    "        oob_score = 0\n",
    "        print(\"====== Out of bag score for each tree ======\")\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            _X = xsamples[i]\n",
    "            _y = ysamples[i]\n",
    "            model.fit(_X, _y)\n",
    "            \n",
    "            _X_test = np.asarray(xsamples_oob[i])                    # calculating oob score for each bootstrapped dataset\n",
    "            _y_test = np.asarray(ysamples_oob[i])\n",
    "            #print(_X_test)\n",
    "            #print(_y_test)\n",
    "            \n",
    "            yhat = model.predict(_X_test)\n",
    "            oob_score += accuracy_score(_y_test, yhat)\n",
    "            print(f\"Tree {i}\", accuracy_score(_y_test, yhat))\n",
    "    \n",
    "        self.avg_oob_score = oob_score / len(self.models)           # the average score\n",
    "        print(\"====== Average out of bag score ======\")\n",
    "        print(self.avg_oob_score)\n",
    "        \n",
    "    # 2. X_test\n",
    "    def predict(self, X): \n",
    "        #make prediction and return the probabilities\n",
    "        predictions = np.zeros((self.B, X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            yhat = model.predict(X)\n",
    "            predictions[i, :] = yhat\n",
    "        return stats.mode(predictions)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Out of bag score for each tree ======\n",
      "Tree 0 1.0\n",
      "Tree 1 0.8571428571428571\n",
      "Tree 2 0.7619047619047619\n",
      "Tree 3 0.9523809523809523\n",
      "Tree 4 0.9523809523809523\n",
      "====== Average out of bag score ======\n",
      "0.9047619047619048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try md\n",
    "model = RandomForest(B=5, bootstrap_ratio = 0.8)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
